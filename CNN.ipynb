{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1EHWW_JiUPaU19oxS05vOowszzOfFCMa2",
          "timestamp": 1527423420497
        },
        {
          "file_id": "1jX4tkk5SsYcuIE4uwQZkleNSucqImh78",
          "timestamp": 1527422387810
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ooczWWt8VHG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This CNN model was trained on the MNIST dataset. The MNIST dataset is a database of handwritten digits that is commonly used for training various image processing systems. This one trains and evaluates without using GPU."
      ]
    },
    {
      "metadata": {
        "id": "RimLQQTIG4YQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import statements"
      ]
    },
    {
      "metadata": {
        "id": "qCGEi51EGjwJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "fd58c8c4-835e-4b69-b8b2-ba3cafcf7c00",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428089231,
          "user_tz": 240,
          "elapsed": 98159,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import all necessary items\n",
        "import time\n",
        "import platform\n",
        "import io\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm \n",
        "\n",
        "# install pytorch and Torchvision\n",
        "def install_pytorch():\n",
        "    os = platform.system()\n",
        "    if os == \"Linux\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
        "    elif os == \"Windows\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl \n",
        "    !pip3 install torchvision\n",
        "    \n",
        "install_pytorch()\n",
        "\n",
        "# now that Pytorch and Torchvision are installed, import the relevant libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl (566.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 566.4MB 60.1MB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5cf18000 @  0x7f97385f21c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.0\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/4b/8b54ab9d37b93998c81b364557dff9f61972c0f650efa0ceaf470b392740/Pillow-5.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 6.3MB/s \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.1.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rtI7ohydHR2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ]
    },
    {
      "metadata": {
        "id": "KZiN5g2CHT9z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download the dataset from PyTorch\n",
        "\n",
        "Import the MNIST dataset using PyTorch tools (PyTorch has an [MNIST Dataset class](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#mnist). Download the MNIST dataset into training and test datasets. "
      ]
    },
    {
      "metadata": {
        "id": "TK9s3iGBHYpH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4f15dd31-f732-4d2a-a49a-d77ed67c628a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428100772,
          "user_tz": 240,
          "elapsed": 1718,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import the necessary libraries \n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# create the training and test datasets\n",
        "train_dataset = MNIST(root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "test_dataset = MNIST(root='../data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YkePuczSHbC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the dataset\n",
        "\n",
        "For training and evaluation purposes, the dataset objects are  wrapped in PyTorch [DataLoader objects](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader).  The function<b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> which divides the dataset automatically in mini-batches. "
      ]
    },
    {
      "metadata": {
        "id": "brZr2pGPHcah",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f7c61e1-3010-4f00-9bf0-dde4ffe9800f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428108448,
          "user_tz": 240,
          "elapsed": 6361,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Dataloader gives object that you can iterate on \n",
        "# will need this to enumerate/train data\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "# checking\n",
        "d = list(train_loader)\n",
        "len(d)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "rMjyDdKuHuC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Take the train_loader set for the following model"
      ]
    },
    {
      "metadata": {
        "id": "WrrWDVgTH22A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "afaf785d-5744-40f3-ba09-da186c89124b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428124271,
          "user_tz": 240,
          "elapsed": 6547,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = list(train_loader)[0][0]\n",
        "x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "O4imaL8YMA8G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network model\n",
        "\n",
        "Define the neural network model in the CNN class below. The CNN class will inherit from the [`nn.Module` class](https://pytorch.org/docs/stable/nn.html#module) (this class includes some neural net boilerplate code and magic methods)."
      ]
    },
    {
      "metadata": {
        "id": "czK3cTZXI2er",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "892d826d-677e-47f0-ca58-7eeadad02435",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428127975,
          "user_tz": 240,
          "elapsed": 545,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import the nn.Module class\n",
        "import torch.nn as nn\n",
        "\n",
        "# defines the convolutional neural network\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            #1x28x28\n",
        "            nn.Conv2d(in_channels=1, \n",
        "                      out_channels=16, \n",
        "                      kernel_size=5, \n",
        "                      stride=1, \n",
        "                      padding=2),\n",
        "            #16x28x28\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            #16x14x14\n",
        "        )\n",
        "        #16x14x14\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, \n",
        "                      out_channels=32, \n",
        "                      kernel_size=5, \n",
        "                      stride=1, \n",
        "                      padding=2),\n",
        "            #32x14x14\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "            #32x7x7\n",
        "        ) \n",
        "        # linearly \n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Linear(32*7*7, 500),\n",
        "            nn.Linear(500, 300),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x): \n",
        "        out = self.block1(x)\n",
        "        out = self.block2(out)\n",
        "        # flatten the dataset\n",
        "        out = out.view(-1, 32*7*7)\n",
        "        out = self.block3(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# convolutional neural network model\n",
        "model = CNN()\n",
        "\n",
        "# print summary of the neural network model to check if everything is fine. \n",
        "print(model)\n",
        "print(\"# parameter: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (block1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block3): Sequential(\n",
            "    (0): Linear(in_features=1568, out_features=500, bias=True)\n",
            "    (1): Linear(in_features=500, out_features=300, bias=True)\n",
            "    (2): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "# parameter:  979158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P4CyGK9-L37u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Print out the new shape of the dataset"
      ]
    },
    {
      "metadata": {
        "id": "GuxkUUUwMLqt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "787c1064-efcf-4169-b92c-f5f3d9a6c36e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527428132899,
          "user_tz": 240,
          "elapsed": 350,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "out = model(x)\n",
        "\n",
        "# shape of dataset before model\n",
        "print(\"Previous shape:\", x.shape)\n",
        "\n",
        "# new shape of dataset\n",
        "print(\"New shape:\", out.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([100, 1, 28, 28])\n",
            "New shape: torch.Size([100, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "woXwpaHbPFaQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the loss\n",
        "\n",
        "Cross-entropy or log loss will be used as the loss function. This loss function is ideal for classification models"
      ]
    },
    {
      "metadata": {
        "id": "fx7dRhtuQixH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bwu_WhkQoPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set the learning rate\n",
        "\n",
        "Set the learning rate on which to train the model."
      ]
    },
    {
      "metadata": {
        "id": "KA9RzlyiQxAF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ystq9JFgQ1wu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "\n",
        "For this optimizer, SGD (Stochastic Gradient Descent) will be used, using the learning rate defined above.  "
      ]
    },
    {
      "metadata": {
        "id": "uaJ1vla3RPiY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8ysiC_UR7i5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train & Evaluate the model\n",
        "\n",
        "Now that the model has been defined, it's time to train & evaluate the model. The model will be trained on epochs of mini-batches (train_loader)."
      ]
    },
    {
      "metadata": {
        "id": "QRu6ujV3SDx_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train\n",
        "\n",
        "The code below is trained on 10 epochs (an epoch is a complete representation of the dataset to be learned).\n",
        "\n",
        "### Evaluate\n",
        "\n",
        "This is very similar to training, except that the gradient is not computed and the parameters are not updated. "
      ]
    },
    {
      "metadata": {
        "id": "KhtNtuyVSJCV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "0e87e86c-939a-47d2-dff8-82870323e5be",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527429014692,
          "user_tz": 240,
          "elapsed": 828810,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "\n",
        "# variable to store the total loss\n",
        "total_loss = []\n",
        "\n",
        "# for loop that iterates over all the epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # variables to store/keep track of the loss and number of iterations\n",
        "    train_loss = 0\n",
        "    num_iter = 0\n",
        "    \n",
        "    # train the model\n",
        "    model.train()\n",
        "    \n",
        "    # Iterate over data.\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "    \n",
        "        # Zero the gradient buffer\n",
        "        # resets the gradient after each epoch so that the gradients don't add up\n",
        "        optimizer.zero_grad()  \n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss.append(loss)\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimize\n",
        "        # loops through all parameters and updates weights by using the gradients \n",
        "        optimizer.step()\n",
        "        # update the training loss and number of iterations\n",
        "        train_loss += loss.data[0]\n",
        "        num_iter += 1\n",
        "    \n",
        "    print('Epoch: {}, Loss: {:.4f}'.format(\n",
        "          epoch+1, train_loss/num_iter))\n",
        "    \n",
        "    # evaluate the model\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for images, labels in test_loader:  \n",
        "          \n",
        "       # Forward\n",
        "       outputs = model(images)\n",
        "       loss = criterion(outputs, labels)  \n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "       # Statistics\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum()\n",
        "       \n",
        "    print('Accuracy on the test set: {}%'.format(100 * correct / total))\n",
        "tf = time.time()\n",
        "print()\n",
        "print(\"time: {} s\" .format(tf-t0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 2.2990\n",
            "Accuracy on the test set: 13%\n",
            "Epoch: 2, Loss: 2.2890\n",
            "Accuracy on the test set: 24%\n",
            "Epoch: 3, Loss: 2.2770\n",
            "Accuracy on the test set: 36%\n",
            "Epoch: 4, Loss: 2.2601\n",
            "Accuracy on the test set: 50%\n",
            "Epoch: 5, Loss: 2.2331\n",
            "Accuracy on the test set: 56%\n",
            "Epoch: 6, Loss: 2.1824\n",
            "Accuracy on the test set: 55%\n",
            "Epoch: 7, Loss: 2.0661\n",
            "Accuracy on the test set: 62%\n",
            "Epoch: 8, Loss: 1.7418\n",
            "Accuracy on the test set: 69%\n",
            "Epoch: 9, Loss: 1.1543\n",
            "Accuracy on the test set: 77%\n",
            "Epoch: 10, Loss: 0.7873\n",
            "Accuracy on the test set: 81%\n",
            "\n",
            "time: 828.4415647983551 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
