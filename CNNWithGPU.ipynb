{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNWithGPU.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1jX4tkk5SsYcuIE4uwQZkleNSucqImh78",
          "timestamp": 1527428734130
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ooczWWt8VHG4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This CNN model was trained on the MNIST dataset. The MNIST dataset is a database of handwritten digits that is commonly used for training varius image processing systems. "
      ]
    },
    {
      "metadata": {
        "id": "RimLQQTIG4YQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import statements"
      ]
    },
    {
      "metadata": {
        "id": "qCGEi51EGjwJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "d7bb4429-cb6c-4760-eef2-fbd0ec3e8f49",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430904703,
          "user_tz": 240,
          "elapsed": 4340,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import all necessary items\n",
        "import time\n",
        "import platform\n",
        "import io\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm \n",
        "\n",
        "# install pytorch and Torchvision\n",
        "def install_pytorch():\n",
        "    os = platform.system()\n",
        "    if os == \"Linux\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
        "    elif os == \"Windows\":\n",
        "        !pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl \n",
        "    !pip3 install torchvision\n",
        "    \n",
        "install_pytorch()\n",
        "\n",
        "# now that Pytorch and Torchvision are installed, import the relevant libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rtI7ohydHR2x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ]
    },
    {
      "metadata": {
        "id": "KZiN5g2CHT9z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download the dataset from PyTorch\n",
        "\n",
        "Import the MNIST dataset using PyTorch tools (PyTorch has an [MNIST Dataset class](https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#mnist). Download the MNIST dataset into training and test datasets. "
      ]
    },
    {
      "metadata": {
        "id": "TK9s3iGBHYpH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import the necessary libraries \n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# create the training and test datasets\n",
        "train_dataset = MNIST(root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "test_dataset = MNIST(root='../data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkePuczSHbC9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the dataset\n",
        "\n",
        "For training and evaluation purposes, the dataset objects are  wrapped in PyTorch [DataLoader objects](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader).  The function<b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> which divides the dataset automatically in mini-batches. "
      ]
    },
    {
      "metadata": {
        "id": "brZr2pGPHcah",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a6833e7-3a21-49e9-caee-6175fd3cebe0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430911580,
          "user_tz": 240,
          "elapsed": 6210,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# Dataloader gives object that you can iterate on \n",
        "# will need this to enumerate/train data\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "# checking\n",
        "d = list(train_loader)\n",
        "len(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "rMjyDdKuHuC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Take the train_loader set for the following model"
      ]
    },
    {
      "metadata": {
        "id": "WrrWDVgTH22A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "766ee48b-0a0e-41c3-cbad-f2db3e91b9c5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430917945,
          "user_tz": 240,
          "elapsed": 6293,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = list(train_loader)[0][0]\n",
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "CJTy9h4hlHJ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use GPU instead of CPU \n",
        "\n",
        "Use the .cuba() function from PyTorch to enable GPU.Using GPU instead of CPU will help make training the model much faster."
      ]
    },
    {
      "metadata": {
        "id": "fbFMiTrQlRRS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1382b9f7-a860-4347-e9e4-a3d1eb74cb61",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430918494,
          "user_tz": 240,
          "elapsed": 513,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "print(\"GPU Available: {}\".format(use_gpu))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O4imaL8YMA8G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network model\n",
        "\n",
        "Define the neural network model in the CNN class below. The CNN class will inherit from the [`nn.Module` class](https://pytorch.org/docs/stable/nn.html#module) (this class includes some neural net boilerplate code and magic methods)."
      ]
    },
    {
      "metadata": {
        "id": "czK3cTZXI2er",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4c88ae48-67ad-421a-d384-9ac8931cbdad",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430918915,
          "user_tz": 240,
          "elapsed": 333,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# import the nn.Module class\n",
        "import torch.nn as nn\n",
        "\n",
        "# defines the convolutional neural network\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            #1x28x28\n",
        "            nn.Conv2d(in_channels=1, \n",
        "                      out_channels=16, \n",
        "                      kernel_size=5, \n",
        "                      stride=1, \n",
        "                      padding=2),\n",
        "            #16x28x28\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            #16x14x14\n",
        "        )\n",
        "        #16x14x14\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, \n",
        "                      out_channels=32, \n",
        "                      kernel_size=5, \n",
        "                      stride=1, \n",
        "                      padding=2),\n",
        "            #32x14x14\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "            #32x7x7\n",
        "        ) \n",
        "        # linearly \n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Linear(32*7*7, 500),\n",
        "            nn.Linear(500, 300),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x): \n",
        "        out = self.block1(x)\n",
        "        out = self.block2(out)\n",
        "        # flatten the dataset\n",
        "        out = out.view(-1, 32*7*7)\n",
        "        out = self.block3(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "# convolutional neural network model\n",
        "model = CNN()\n",
        "\n",
        "# if using GPU\n",
        "if use_gpu:\n",
        "  # switch model to GPU\n",
        "  model.cuda()\n",
        "\n",
        "# print summary of the neural network model to check if everything is fine. \n",
        "print(model)\n",
        "print(\"# parameter: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (block1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (block3): Sequential(\n",
            "    (0): Linear(in_features=1568, out_features=500, bias=True)\n",
            "    (1): Linear(in_features=500, out_features=300, bias=True)\n",
            "    (2): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "# parameter:  979158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Txcv5mtLt8Bp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cec12d55-8e3e-4375-a9c7-3cd8af1dcbe7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430170786,
          "user_tz": 240,
          "elapsed": 292,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "P4CyGK9-L37u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Print out the new shape of the dataset"
      ]
    },
    {
      "metadata": {
        "id": "GuxkUUUwMLqt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "09c7a12f-4d54-484e-f4aa-b2d34dbbb21f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527430919516,
          "user_tz": 240,
          "elapsed": 471,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x = x.cuda()\n",
        "out = model(x)\n",
        "\n",
        "# shape of dataset before model\n",
        "print(\"Previous shape:\", x.shape)\n",
        "\n",
        "# new shape of dataset\n",
        "print(\"New shape:\", out.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([100, 1, 28, 28])\n",
            "New shape: torch.Size([100, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "woXwpaHbPFaQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the loss\n",
        "\n",
        "Cross-entropy or log loss will be used as the loss function. This loss function is ideal for classification models"
      ]
    },
    {
      "metadata": {
        "id": "fx7dRhtuQixH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bwu_WhkQoPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set the learning rate\n",
        "\n",
        "Set the learning rate on which to train the model."
      ]
    },
    {
      "metadata": {
        "id": "KA9RzlyiQxAF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ystq9JFgQ1wu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer\n",
        "\n",
        "For this optimizer, SGD (Stochastic Gradient Descent) will be used, using the learning rate defined above.  "
      ]
    },
    {
      "metadata": {
        "id": "uaJ1vla3RPiY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8ysiC_UR7i5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train & Evaluate the model\n",
        "\n",
        "Now that the model has been defined, it's time to train & evaluate the model. The model will be trained on epochs of mini-batches (train_loader)."
      ]
    },
    {
      "metadata": {
        "id": "QRu6ujV3SDx_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train\n",
        "\n",
        "The code below is trained on 10 epochs (an epoch is a complete representation of the dataset to be learned).\n",
        "\n",
        "### Evaluate\n",
        "\n",
        "This is very similar to training, except that the gradient is not computed and the parameters are not updated. "
      ]
    },
    {
      "metadata": {
        "id": "KhtNtuyVSJCV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "d4c34d57-6513-41a5-95cb-f4abac3f2dff",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527431086440,
          "user_tz": 240,
          "elapsed": 145532,
          "user": {
            "displayName": "Helen Gezahegn",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "109917725328175669605"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "\n",
        "# variable to store the total loss\n",
        "total_loss = []\n",
        "\n",
        "# for loop that iterates over all the epochs\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    # variables to store/keep track of the loss and number of iterations\n",
        "    train_loss = 0\n",
        "    num_iter = 0\n",
        "    \n",
        "    # train the model\n",
        "    model.train()\n",
        "    \n",
        "    # Iterate over data.\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "      \n",
        "        # if GPU is available \n",
        "        if use_gpu:\n",
        "          # switch tensor type to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "        # Zero the gradient buffer\n",
        "        # resets the gradient after each epoch so that the gradients don't add up\n",
        "        optimizer.zero_grad()  \n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss.append(loss)\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimize\n",
        "        # loops through all parameters and updates weights by using the gradients \n",
        "        optimizer.step()\n",
        "        # update the training loss and number of iterations\n",
        "        train_loss += loss.data[0]\n",
        "        num_iter += 1\n",
        "    \n",
        "    print('Epoch: {}, Loss: {:.4f}'.format(\n",
        "          epoch+1, train_loss/num_iter))\n",
        "    \n",
        "    # evaluate the model\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for images, labels in test_loader:  \n",
        "       \n",
        "       # if GPU is available \n",
        "       if use_gpu:\n",
        "          # switch tensor type to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          \n",
        "       # Forward\n",
        "       outputs = model(images)\n",
        "       loss = criterion(outputs, labels)  \n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "       # Statistics\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum()\n",
        "       \n",
        "    print('Accuracy on the test set: {}%'.format(100 * correct / total))\n",
        "tf = time.time()\n",
        "print()\n",
        "print(\"time: {} s\" .format(tf-t0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 2.2970\n",
            "Accuracy on the test set: 16%\n",
            "Epoch: 2, Loss: 2.2898\n",
            "Accuracy on the test set: 24%\n",
            "Epoch: 3, Loss: 2.2811\n",
            "Accuracy on the test set: 28%\n",
            "Epoch: 4, Loss: 2.2694\n",
            "Accuracy on the test set: 47%\n",
            "Epoch: 5, Loss: 2.2517\n",
            "Accuracy on the test set: 55%\n",
            "Epoch: 6, Loss: 2.2208\n",
            "Accuracy on the test set: 56%\n",
            "Epoch: 7, Loss: 2.1572\n",
            "Accuracy on the test set: 56%\n",
            "Epoch: 8, Loss: 1.9955\n",
            "Accuracy on the test set: 58%\n",
            "Epoch: 9, Loss: 1.6059\n",
            "Accuracy on the test set: 68%\n",
            "Epoch: 10, Loss: 1.0551\n",
            "Accuracy on the test set: 78%\n",
            "Epoch: 11, Loss: 0.7247\n",
            "Accuracy on the test set: 82%\n",
            "Epoch: 12, Loss: 0.5934\n",
            "Accuracy on the test set: 84%\n",
            "Epoch: 13, Loss: 0.5247\n",
            "Accuracy on the test set: 85%\n",
            "Epoch: 14, Loss: 0.4789\n",
            "Accuracy on the test set: 87%\n",
            "Epoch: 15, Loss: 0.4440\n",
            "Accuracy on the test set: 88%\n",
            "\n",
            "time: 145.17359590530396 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}